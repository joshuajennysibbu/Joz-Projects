{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bitcoin Mining.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UmfiC4seARY"
      },
      "source": [
        "import requests\n",
        "import torch\n",
        "import hashlib\n",
        "import numpy as np\n",
        "import json\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import string \n",
        "import random as r\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2jyBA3NeEes"
      },
      "source": [
        "# !cp /content/drive/MyDrive/model_connector.ckpt /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q_xQtawgOmB"
      },
      "source": [
        "# !cp /content/drive/MyDrive/model_input.ckpt /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQy2xiR9gQ2I"
      },
      "source": [
        "# !cp /content/drive/MyDrive/model_output.ckpt /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDJlQgXtgT8H"
      },
      "source": [
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdyo8b2igU2_"
      },
      "source": [
        "num_classes=32\n",
        "num_epochs=2000\n",
        "lr=0.0001\n",
        "input_size=1\n",
        "sequence_length=64\n",
        "hidden_size=32\n",
        "num_layers=2\n",
        "batch_size=32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j5br7YdgZKa"
      },
      "source": [
        "#after getting file return json format block and transaction\n",
        "def fetch_data(i):\n",
        "    blockset='/content/drive/MyDrive/blockset.txt'\n",
        "    with open(blockset, 'r') as f:\n",
        "      dataset = json.loads(f.read())\n",
        "    response = requests.get(\"https://blockchain.info/rawblock/{}\".format(dataset[i]))\n",
        "    data = response.json()\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjNekccNgZ08"
      },
      "source": [
        "def input_preprocessing(input):\n",
        "  new_input={'ver':input.get('ver'),\n",
        "             'prev_block':input.get('prev_block'),\n",
        "             'mrkl_root':input.get('mrkl_root'),\n",
        "             'time':input.get('time'),\n",
        "             'bits':input.get('bits')}\n",
        "  return new_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Rfgs0oCgeAU"
      },
      "source": [
        "def output_checker(input,pred_nonce):\n",
        "  new_input={'ver':input.get('ver'),\n",
        "             'prev_block':input.get('prev_block'),\n",
        "             'mrkl_root':input.get('mrkl_root'),\n",
        "             'time':input.get('time'),\n",
        "             'bits':input.get('bits'),\n",
        "             'nonce':pred_nonce}\n",
        "  return new_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-Tr4rRFgerQ"
      },
      "source": [
        "def target_preprocessing(bits):\n",
        "  #bits='0x1e03a30c'\n",
        "  exponent=bits[2:4]\n",
        "  coefficient=bits[4:]\n",
        "  exponents=int('8',16)*(int(exponent,16)-int('3',16))\n",
        "  target=int(coefficient,16)*(int('2',16))**exponents\n",
        "  targets=format(target,'x')\n",
        "  target=str(targets).zfill(64)\n",
        "  return target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqjMxAmTggTj"
      },
      "source": [
        "#sha256 return hash output\n",
        "def hash_256(string):\n",
        "  new_out=json.dumps(string).encode('utf-8')\n",
        "  return hashlib.sha256(new_out).hexdigest()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cd_sVGCgiGl"
      },
      "source": [
        "def target_cal(hash,target):\n",
        "  reward=0\n",
        "  if hash.startswith(target):\n",
        "    print('******************************Congrats You find Golden Nonce*******************************************************************')\n",
        "    reward+=1\n",
        "    return True,reward\n",
        "  else:\n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM6Pr5Vxgj1i"
      },
      "source": [
        "def prefix(target):\n",
        "  for i in range(0,len(target)):\n",
        "    if target[i]=='f':\n",
        "      prefix_value=i\n",
        "      break\n",
        "  prefix=target[:prefix_value]\n",
        "  return prefix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eXfvQSSgmRP"
      },
      "source": [
        "def output_hash_generator(n):\n",
        "  n=len(n)\n",
        "  zeros='0'*n\n",
        "  zeros=list(zeros)\n",
        "  k=64-n\n",
        "  chars=['A','B','C','D','E','F','0','1','2','3','4','5','6','7','8','9']\n",
        "  data1=r.choices(chars,k=64-n)\n",
        "  data=zeros+data1\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0upov1ugoAO"
      },
      "source": [
        "def encoding(dataset):\n",
        "  lst=[]\n",
        "  for i in dataset:\n",
        "    data=int(i,16)\n",
        "    lst.append(data)\n",
        "\n",
        "  data=torch.tensor(lst)\n",
        "  data=data.unsqueeze(0)\n",
        "  data=torch.transpose(data,0,1)\n",
        "  #data=data.unsqueeze(0)\n",
        "\n",
        "  data=torch.tensor(data,dtype=torch.float)\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkBitLlDgp5z"
      },
      "source": [
        "def getting_nonce(input):\n",
        "  nonce=input.get('nonce')\n",
        "  return nonce"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRUdkytfgruS"
      },
      "source": [
        "def wrapper(dataset):\n",
        "    \n",
        "    dataset=input_preprocessing(dataset)\n",
        "    dataset=hash_256(dataset)\n",
        "    dataset=encoding(dataset)\n",
        "    \n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Yl3ARn3gtKe"
      },
      "source": [
        "def output_wrapper():\n",
        "  out=output_checker(input,pred_nonce)\n",
        "  out=hash_256(out)\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_rJgpcGgu22"
      },
      "source": [
        "def converter(ins):\n",
        "  lst=[]\n",
        "  for i in ins:\n",
        "    lst+=i\n",
        "    lst=''.join(lst)\n",
        "  return lst"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYnerOdcgwkx"
      },
      "source": [
        "def weight_init(tensor):\n",
        "  return torch.nn.init.xavier_normal_(tensor, gain=1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxQEo400gyxS"
      },
      "source": [
        "def nonce_converter(dat):\n",
        "  dat=str(dat.item())\n",
        "  for i in range(len(dat)):\n",
        "    if dat[i]=='.':\n",
        "      index=i\n",
        "  counter=0\n",
        "  dat=dat[index+1::]\n",
        "\n",
        "  return dat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZPw-sjog0cG"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self):\n",
        "    path='/content/drive/MyDrive/dataset .txt'\n",
        "    with open(path, 'r') as f:\n",
        "      dataset = json.loads(f.read())\n",
        "    self.dataset=dataset\n",
        "  \n",
        "  def __len__(self):\n",
        "    return batch_size\n",
        "  \n",
        "  def __getitem__(self,index):\n",
        "    global aamada\n",
        "    aamada=self.dataset[index]\n",
        "    dict_dataset=dict(self.dataset[index])\n",
        "    bits=dict_dataset[\"bits\"]   #take bits field from data\n",
        "    nonce=dict_dataset[\"nonce\"]\n",
        "    bits=hex(bits)  #Convert bit to hex\n",
        "    target_bit=target_preprocessing(bits)   #Preprocessing bit to hash\n",
        "    target_bit=prefix(target_bit)   #It will find prefix\n",
        "    target_hash=output_hash_generator(target_bit)  #It will generate random output from prefix data\n",
        "    target_hash=converter(target_hash)   #Convert target hash to list\n",
        "    target_encoded=encoding(target_hash)\n",
        "    input_data=wrapper(self.dataset[index])\n",
        "    return input_data,target_encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eZz85lHg2l8"
      },
      "source": [
        "loader=Dataset()\n",
        "train_loader=torch.utils.data.DataLoader(loader,batch_size=batch_size,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKqThpi5g5B_"
      },
      "source": [
        "class Connector(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,num_layers,num_classes,batch_size,decider):\n",
        "    super(Connector,self).__init__()\n",
        "    self.num_layers=num_layers\n",
        "    self.hidden_size=hidden_size\n",
        "    self.input_size=input_size\n",
        "    self.num_classes=num_classes\n",
        "    self.decider=decider\n",
        "    \n",
        "    self.GRU_3=nn.GRU(input_size*64,hidden_size,num_layers*2,batch_first=True,bidirectional=True)\n",
        "    self.GRU_4=nn.GRU(input_size*64,hidden_size,num_layers*2,batch_first=True,bidirectional=True)\n",
        " \n",
        "    self.fc1=nn.Linear(131072,hidden_size*24,bias=True)\n",
        "    self.fc2=nn.Linear(hidden_size*24,hidden_size,bias=True)\n",
        "    self.fc3=nn.Linear(hidden_size,1,bias=True)\n",
        "\n",
        "    self.activation_out=nn.ReLU()\n",
        "    self.acti=nn.Sigmoid()\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "\n",
        "    # self.batch_norm=nn.BatchNorm1d(hidden_size)\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "        h3=torch.zeros(self.num_layers*4,batch_size,self.hidden_size)\n",
        "        h3=weight_init(h3)\n",
        "        h4=torch.zeros(self.num_layers*4,batch_size,self.hidden_size)\n",
        "        h4=weight_init(h4)\n",
        "        if self.decider:\n",
        "          out,_=self.GRU_3(x,h3)\n",
        "          out=self.acti(out)\n",
        "          # out=self.batch_norm(out)\n",
        "          out,_=self.GRU_4(out,h4)\n",
        "          out=self.acti(out)\n",
        "          # out=self.batch_norm(out)\n",
        "          # out=out.reshape(out.shape[0],-1)\n",
        "          out=torch.flatten(out)\n",
        "          out=self.fc1(out)\n",
        "          out_hash=self.fc2(out)\n",
        "          # out_hash=out_hash[1]\n",
        "          return out_hash\n",
        "        else:\n",
        "          out_nonce=self.fc3(x)\n",
        "          out=torch.reshape(out_nonce[0],(1,1))\n",
        "          out_nonce=nonce_converter(out)\n",
        "          out_nonce=int(out_nonce)\n",
        "          out_nonce=torch.tensor(out_nonce,dtype=torch.int32)\n",
        "          out_nonce=abs(out_nonce)\n",
        "          out_nonce=torch.tensor(out_nonce)\n",
        "\n",
        "          return out_nonce\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTgi3VV0g7HA"
      },
      "source": [
        "class GRU(nn.Module):\n",
        "    def __init__(self,input_size,hidden_size,num_layers,num_classes,batch_size):\n",
        "        super(GRU,self).__init__()\n",
        "        self.num_layers=num_layers\n",
        "        self.hidden_size=hidden_size\n",
        "        self.input_size=input_size\n",
        "        self.num_classes=num_classes\n",
        "        \n",
        "        self.GRU_0=nn.GRU(input_size,hidden_size,num_layers*2,batch_first=True)\n",
        "        # self.GRU_1=nn.GRU(input_size*64,hidden_size*2,num_layers*2,batch_first=True)\n",
        "        # self.GRU_2=nn.GRU(input_size*256,hidden_size*8,num_layers*2,batch_first=True)\n",
        "        self.acti=nn.Sigmoid()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        # self.batch_norm=nn.BatchNorm1d(hidden_size)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        h0=torch.zeros(self.num_layers*2,batch_size,self.hidden_size)\n",
        "        h0=weight_init(h0)\n",
        "        # h1=torch.zeros(self.num_layers*2,batch_size,self.hidden_size*2)\n",
        "        # h1=weight_init(h1)\n",
        "        # h2=torch.zeros(self.num_layers*2,batch_size,self.hidden_size*8)\n",
        "        # h2=weight_init(h2)\n",
        "        \n",
        " \n",
        "        #Forward Propagation\n",
        "        out,_=self.GRU_0(x,h0)\n",
        "        out=self.acti(out)\n",
        "        # out=self.batch_norm(out)\n",
        "        # out,_=self.GRU_1(out,h1)\n",
        "        # out=self.acti(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX-n1r4Fg8zF"
      },
      "source": [
        "model_input=GRU(input_size, hidden_size, num_layers, num_classes,batch_size)\n",
        "model_connector_hash=Connector(input_size, hidden_size, num_layers, num_classes,batch_size,decider=True)\n",
        "model_connector_nonce=Connector(input_size, hidden_size, num_layers, num_classes,batch_size,decider=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9gsi258g-sE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cd2bccc0-89a1-4f29-9347-c78dea242c87"
      },
      "source": [
        "criterion=nn.MSELoss()\n",
        "nonce_acti=nn.Tanh()\n",
        "input_acti=nn.Sigmoid()\n",
        "criterion_2=nn.L1Loss()\n",
        "\n",
        "optimizer_hash = torch.optim.Adadelta(model_connector_hash.parameters(), lr=lr,weight_decay=0.0001) \n",
        "optimizer_nonce = torch.optim.Adadelta(model_connector_nonce.parameters(), lr=lr,weight_decay=0.0001) \n",
        "\n",
        "loss_n=[]\n",
        "loss_h=[]\n",
        "nonce_val=[]\n",
        "epoch_val=[]\n",
        "counter=0\n",
        "\n",
        "for i in tqdm(range(0,num_epochs)):\n",
        "  for j,(input, output) in enumerate(train_loader):\n",
        "        input=input_acti(input)\n",
        "        output=input_acti(output)\n",
        "        score=model_input(input)  #feed input\n",
        "  \n",
        "        \n",
        "        score_2=model_input(output)   #Feed target data input to modelone\n",
        "\n",
        "        real_input=torch.cat([score,score_2],dim=2)  #Concatenate two different input for second model\n",
        "        out_hash=model_connector_hash(real_input)    #Connector model for hash\n",
        "        out_nonce=model_connector_nonce(out_hash)     #Connector model for nonce\n",
        "\n",
        "        nonce=getting_nonce(aamada)    #Get nonce from data\n",
        "        outputwithnonce=output_checker(aamada,out_nonce.item())   #It will generate dictionary data with real data and pred nonce\n",
        "        outputhash=hash_256(outputwithnonce)  #It will convert pred nonce dictionary to hash\n",
        "        encoded_output=encoding(outputhash)   #Hash encoding\n",
        "        \n",
        "        target_hash=aamada.get('next_block')\n",
        "        target_hash=str(target_hash)\n",
        "        target=target_cal(outputhash,target_hash)   #Just check target   \n",
        "\n",
        "        loss_hash=criterion(out_hash,output)   #loss cal for hash \n",
        "        \n",
        "\n",
        "        nonce=torch.tensor(nonce)\n",
        "        out_nonce=torch.tensor(out_nonce)\n",
        "        nonces=torch.log(nonce)\n",
        "        out_nonces=torch.log(out_nonce)\n",
        "        loss_nonce=criterion_2(out_nonces,nonces)   #loss for nonce\n",
        "\n",
        "        loss_nonce=torch.tensor(loss_nonce,requires_grad=True)\n",
        "        nonce_val.append(out_nonce)\n",
        "        loss_h.append(loss_hash)\n",
        "        loss_n.append(loss_nonce)\n",
        "        epoch_val.append(i)\n",
        "        \n",
        "        optimizer_hash.zero_grad()\n",
        "        loss_hash.backward()\n",
        "        optimizer_hash.step()\n",
        "        \n",
        "\n",
        "        optimizer_nonce.zero_grad()\n",
        "        loss_nonce.backward()\n",
        "        optimizer_nonce.step()\n",
        "\n",
        "\n",
        "      #  if counter%2==0:\n",
        "        # print('Epoch[{}/{}],loss hash:{},loss_nonce:{},Expected nonce:{},Predicted nonce:{}'\n",
        "        #     .format(j,len(train_loader),loss_h,loss_n,output,nonce))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/2000 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 64, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/2000 [00:04<2:23:47,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch[0/1],loss hash:[tensor(0.0368, grad_fn=<MseLossBackward0>)],loss_nonce:[tensor(0.8460, requires_grad=True)],Expected nonce:tensor([[[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [0.9997],\n",
            "         [0.9991],\n",
            "         [1.0000]],\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [0.9933],\n",
            "         [0.9991],\n",
            "         [1.0000]],\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [0.9975],\n",
            "         [1.0000],\n",
            "         [1.0000]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [0.9820],\n",
            "         [0.9999],\n",
            "         [1.0000]],\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [0.9975],\n",
            "         [0.9991],\n",
            "         [0.9991]],\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [0.5000],\n",
            "         [1.0000],\n",
            "         [0.9991]]]),Predicted nonce:1639830024\n",
            "torch.Size([32, 64, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 2/2000 [00:05<1:30:38,  2.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch[0/1],loss hash:[tensor(0.0368, grad_fn=<MseLossBackward0>), tensor(0.0361, grad_fn=<MseLossBackward0>)],loss_nonce:[tensor(0.8460, requires_grad=True), tensor(0.7222, requires_grad=True)],Expected nonce:tensor([[[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [1.0000],\n",
            "         [0.7311],\n",
            "         [0.9933]],\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [0.9997],\n",
            "         [1.0000],\n",
            "         [1.0000]],\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [0.9991],\n",
            "         [1.0000],\n",
            "         [0.9999]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [1.0000],\n",
            "         [0.7311],\n",
            "         [1.0000]],\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [0.7311],\n",
            "         [0.9526],\n",
            "         [0.7311]],\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [1.0000],\n",
            "         [0.9997],\n",
            "         [0.9526]]]),Predicted nonce:4064360242\n",
            "torch.Size([32, 64, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 3/2000 [00:07<1:14:03,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch[0/1],loss hash:[tensor(0.0368, grad_fn=<MseLossBackward0>), tensor(0.0361, grad_fn=<MseLossBackward0>), tensor(0.0353, grad_fn=<MseLossBackward0>)],loss_nonce:[tensor(0.8460, requires_grad=True), tensor(0.7222, requires_grad=True), tensor(0.4617, requires_grad=True)],Expected nonce:tensor([[[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [0.9820],\n",
            "         [1.0000],\n",
            "         [0.9933]],\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [1.0000],\n",
            "         [1.0000],\n",
            "         [1.0000]],\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [1.0000],\n",
            "         [0.9991],\n",
            "         [1.0000]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [0.9997],\n",
            "         [0.9820],\n",
            "         [1.0000]],\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [0.9991],\n",
            "         [1.0000],\n",
            "         [1.0000]],\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [0.8808],\n",
            "         [0.8808],\n",
            "         [1.0000]]]),Predicted nonce:2850094635\n",
            "torch.Size([32, 64, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 4/2000 [00:09<1:06:21,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch[0/1],loss hash:[tensor(0.0368, grad_fn=<MseLossBackward0>), tensor(0.0361, grad_fn=<MseLossBackward0>), tensor(0.0353, grad_fn=<MseLossBackward0>), tensor(0.0356, grad_fn=<MseLossBackward0>)],loss_nonce:[tensor(0.8460, requires_grad=True), tensor(0.7222, requires_grad=True), tensor(0.4617, requires_grad=True), tensor(2.0248, requires_grad=True)],Expected nonce:tensor([[[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [0.9999],\n",
            "         [1.0000],\n",
            "         [1.0000]],\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [1.0000],\n",
            "         [1.0000],\n",
            "         [1.0000]],\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [0.9933],\n",
            "         [1.0000],\n",
            "         [0.9997]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [1.0000],\n",
            "         [0.9933],\n",
            "         [0.9991]],\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [0.9997],\n",
            "         [1.0000],\n",
            "         [0.5000]],\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [1.0000],\n",
            "         [1.0000],\n",
            "         [1.0000]]]),Predicted nonce:208296255\n",
            "torch.Size([32, 64, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 5/2000 [00:10<1:01:48,  1.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch[0/1],loss hash:[tensor(0.0368, grad_fn=<MseLossBackward0>), tensor(0.0361, grad_fn=<MseLossBackward0>), tensor(0.0353, grad_fn=<MseLossBackward0>), tensor(0.0356, grad_fn=<MseLossBackward0>), tensor(0.0370, grad_fn=<MseLossBackward0>)],loss_nonce:[tensor(0.8460, requires_grad=True), tensor(0.7222, requires_grad=True), tensor(0.4617, requires_grad=True), tensor(2.0248, requires_grad=True), tensor(0.2207, requires_grad=True)],Expected nonce:tensor([[[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [1.0000],\n",
            "         [1.0000],\n",
            "         [0.9991]],\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [0.9526],\n",
            "         [1.0000],\n",
            "         [0.9999]],\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [0.7311],\n",
            "         [0.5000],\n",
            "         [1.0000]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [0.8808],\n",
            "         [0.8808],\n",
            "         [0.8808]],\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [0.9991],\n",
            "         [1.0000],\n",
            "         [1.0000]],\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [0.9997],\n",
            "         [1.0000],\n",
            "         [0.9997]]]),Predicted nonce:1437882917\n",
            "torch.Size([32, 64, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 6/2000 [00:12<59:09,  1.78s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch[0/1],loss hash:[tensor(0.0368, grad_fn=<MseLossBackward0>), tensor(0.0361, grad_fn=<MseLossBackward0>), tensor(0.0353, grad_fn=<MseLossBackward0>), tensor(0.0356, grad_fn=<MseLossBackward0>), tensor(0.0370, grad_fn=<MseLossBackward0>), tensor(0.0362, grad_fn=<MseLossBackward0>)],loss_nonce:[tensor(0.8460, requires_grad=True), tensor(0.7222, requires_grad=True), tensor(0.4617, requires_grad=True), tensor(2.0248, requires_grad=True), tensor(0.2207, requires_grad=True), tensor(1.2020, requires_grad=True)],Expected nonce:tensor([[[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [0.9997],\n",
            "         [0.9933],\n",
            "         [0.9820]],\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [0.9997],\n",
            "         [0.8808],\n",
            "         [0.9820]],\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [1.0000],\n",
            "         [0.9933],\n",
            "         [1.0000]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [1.0000],\n",
            "         [0.9997],\n",
            "         [0.9991]],\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [1.0000],\n",
            "         [1.0000],\n",
            "         [1.0000]],\n",
            "\n",
            "        [[0.5000],\n",
            "         [0.5000],\n",
            "         [0.5000],\n",
            "         ...,\n",
            "         [1.0000],\n",
            "         [0.9997],\n",
            "         [0.5000]]]),Predicted nonce:1716931356\n",
            "torch.Size([32, 64, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 6/2000 [00:13<1:14:20,  2.24s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-3f112ddde45c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0moptimizer_hash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mloss_hash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0moptimizer_hash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adadelta.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    110\u001b[0m                        \u001b[0mrho\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                        \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                        weight_decay=weight_decay)\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madadelta\u001b[0;34m(params, grads, square_avgs, acc_deltas, lr, rho, eps, weight_decay)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0msquare_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msquare_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc_delta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rplmvjWhBuD"
      },
      "source": [
        "# connector = torch.load('model_connector.ckpt')\n",
        "# model_connector.load_state_dict(connector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NJjcPC5hCXM"
      },
      "source": [
        "# modelinput = torch.load('model_input.ckpt')\n",
        "# model_input.load_state_dict(modelinput)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbicVX4ShDuT"
      },
      "source": [
        "# modeloutput = torch.load('model_output.ckpt')\n",
        "# model_output.load_state_dict(modeloutput)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbSZS5TohFhB"
      },
      "source": [
        "# torch.save(model_input.state_dict(),'model_input.ckpt')\n",
        "# torch.save(model_connector_hash.state_dict(),'model_connector_hash.ckpt')\n",
        "# torch.save(model_connector_nonce.state_dict(),'model_connector_nonce.ckpt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1q8frophHlJ"
      },
      "source": [
        "# from google.colab import files\n",
        "# files.download('model_input.ckpt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4ZO4P9U2-4H"
      },
      "source": [
        "# from google.colab import files\n",
        "# files.download('model_connector_hash.ckpt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISLz8mdSyicP"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('model_connector_nonce.ckpt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}